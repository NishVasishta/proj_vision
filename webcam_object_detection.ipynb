{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and function definitions\n",
    "\n",
    "#@title Imports and function definitions\n",
    "\n",
    "# Runs with stable version tensorflow 2.1.0.\n",
    "\n",
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time\n",
    "\n",
    "#for webcam\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Print Tensorflow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "\n",
    "\n",
    "### Helper functions for downloading images and for visualization.\n",
    "\n",
    "\"\"\"Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality.\n",
    "\"\"\"\n",
    "\n",
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(20, 15))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "\n",
    "def download_and_resize_image(url, new_width=256, new_height=256, display=False):\n",
    "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "  response = urlopen(url)\n",
    "  image_data = response.read()\n",
    "  image_data = BytesIO(image_data)\n",
    "  pil_image = Image.open(image_data)\n",
    "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "  print(\"Image downloaded to %s.\" % filename)\n",
    "  if display:\n",
    "    display_image(pil_image)\n",
    "  return filename\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "  #Adds a bounding box to an image.\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.5):\n",
    "  #Overlay labeled boxes on an image with formatted scores and label names.\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                              25)\n",
    "  except IOError:\n",
    "    print(\"Font not found, using default font.\")\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      draw_bounding_box_on_image(\n",
    "          image_pil,\n",
    "          ymin,\n",
    "          xmin,\n",
    "          ymax,\n",
    "          xmax,\n",
    "          color,\n",
    "          font,\n",
    "          display_str_list=[display_str])\n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  return image\n",
    "print(\"executed successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply module\n",
    "\"\"\"\n",
    "Load a public image from Open Images v4, save locally, and display.\n",
    "\"\"\"\n",
    "\n",
    "image_url = \"https://farm1.staticflickr.com/4032/4653948754_c0d768086b_o.jpg\"  #@param\n",
    "#downloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)\n",
    "downloaded_image_path = r\"C:\\Users\\Namratha\\AppData\\Local\\Temp\\hotel_pic_1.jpg\"\n",
    "\"\"\"Pick an object detection module and apply on the downloaded image. Modules:\n",
    "* **FasterRCNN+InceptionResNet V2**: high accuracy,\n",
    "* **ssd+mobilenet V2**: small and fast.\n",
    "\"\"\"\n",
    "\n",
    "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
    "\n",
    "detector = hub.load(module_handle).signatures['default']\n",
    "\n",
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  return img\n",
    "print(\"executed successfully again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(detector, path):\n",
    "    while(True):\n",
    "      ret, img_np = cap.read()  \n",
    "     # img = load_img(path)\n",
    "\n",
    "      converted_img  = tf.image.convert_image_dtype(img_np, tf.float32)[tf.newaxis, ...]\n",
    "      start_time = time.time()\n",
    "      result = detector(converted_img)\n",
    "      end_time = time.time()\n",
    "\n",
    "      result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "      print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "      print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "      image_with_boxes = draw_boxes(\n",
    "          img_np, result[\"detection_boxes\"],\n",
    "          result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "      #display_image(image_with_boxes)\n",
    "      cv2.imshow('check1', cv2.resize(image_with_boxes, (800,600)))\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "print(\"executed successfully again..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_detector(detector, downloaded_image_path)\n",
    "print(\"executed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"### More images\n",
    "Perform inference on some additional images with time tracking.\n",
    "\"\"\"\n",
    "\n",
    "image_urls = [\"https://farm1.staticflickr.com/5041/5240239550_1134c76db8_o.jpg\",\n",
    "              \"https://farm6.staticflickr.com/2598/4138342721_06f6e177f3_o.jpg\",\n",
    "              \"https://c4.staticflickr.com/9/8322/8053836633_6dc507f090_o.jpg\"]\n",
    "\n",
    "for image_url in image_urls:\n",
    "  start_time = time.time()\n",
    "  image_path = download_and_resize_image(image_url, 640, 480)\n",
    "  run_detector(detector, image_path)\n",
    "  end_time = time.time()\n",
    "  print(\"Inference time:\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
